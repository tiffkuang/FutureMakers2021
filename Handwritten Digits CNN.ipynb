{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9159ff5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Screen Shot 2021-02-14 at 12.12.41 PM.png', 'Screen Shot 2021-02-18 at 4.02.27 PM.png', 'Screen Shot 2021-06-09 at 1.14.23 AM.png', 'housing.csv', 'housepricedata.csv', 'Classification Practice.ipynb', 'Salary_Data.csv', 't10k-images-idx3-ubyte', 'Untitled1.ipynb', 'lab10_1.cpp', 'House Price Predictions .ipynb', '.DS_Store', 'Screen Shot 2021-05-12 at 12.40.06 PM.png', 'Screen Shot 2021-04-21 at 11.33.54 PM.png', 'Screen Shot 2021-02-17 at 5.29.41 PM.png', 'Screen Shot 2021-05-03 at 11.20.03 PM.png', 'archive', 'Screen Shot 2021-05-12 at 11.42.29 AM.png', 'Screen Shot 2021-05-12 at 12.56.31 PM.png', '.localized', 'Relocated Items.nosync', 'Screen Shot 2021-06-21 at 10.06.51 AM.png', 'Untitled.ipynb', 'Screen Shot 2021-04-24 at 1.07.52 PM.png', 'Screen Shot 2021-04-22 at 10.12.20 AM.png', 'Screen Shot 2021-06-29 at 10.56.46 PM.png', 'Screen Shot 2021-04-23 at 2.41.51 AM.png', 'Screen Shot 2021-02-18 at 4.02.19 PM.png', 't10k-labels-idx1-ubyte', 'Untitled2.ipynb', 'Screen Shot 2021-04-28 at 12.52.38 PM.png', 'Adar_anthony', 'Tiffany Kuang District Sunset Stickers Receipt.png', 'Screen Shot 2021-05-27 at 2.21.32 PM.png', 'Screen Shot 2021-07-13 at 9.54.29 AM.png', 'Screen Shot 2021-04-21 at 10.10.50 AM.png', 'Data.csv', 'Screen Shot 2021-04-11 at 1.38.19 AM.png', 'Screen Shot 2021-04-10 at 10.26.11 PM.png', 'train-images-idx3-ubyte', 'Screen Shot 2021-05-05 at 11.05.15 PM.png', 'Screen Shot 2021-02-14 at 12.12.33 PM.png', 'Screen Shot 2021-04-14 at 10.56.22 PM.png', 'Day 8 Action Item.ipynb', 'Screen Shot 2021-05-08 at 9.25.46 AM.png', 'Regression Practice.ipynb', 'Sarcasm_Headlines_Dataset_v2.json', 'Screen Shot 2021-05-19 at 6.21.16 AM.png', '.ipynb_checkpoints', 'Screen Shot 2021-04-19 at 1.20.25 PM.png', 'Screen Shot 2021-05-03 at 11.47.04 AM.png', 'Screen Shot 2021-06-28 at 11.41.28 PM.png', 'Day 9.ipynb', 'Screen Shot 2021-05-12 at 12.44.12 PM.png', 'Screen Shot 2021-06-16 at 10.21.15 PM.png', 'Screen Shot 2021-05-02 at 3.46.13 PM.png', 'train-images-idx3-ubyte.gz', 'yearlyCalendar.txt', 'lab9_3.cpp', 'train-labels-idx1-ubyte', 'Social_Network_Ads.csv', 'Screen Shot 2021-05-05 at 11.05.11 PM.png', 'Preprocessing Practice.ipynb', 'Screen Shot 2021-04-20 at 10.14.02 AM.png', 'lab9_1.cpp', 'Screen Shot 2021-02-12 at 10.30.08 AM.png']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# import warnings\n",
    "import warnings\n",
    "# filter warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf \n",
    "import os\n",
    "print(os.listdir(\"../desktop\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "02fb2ec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c6a8d7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape:  (60000, 28, 28)\n",
      "x_test shape:  (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# normalize the data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "print(\"x_train.shape: \", x_train.shape)\n",
    "print(\"x_test shape: \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c9a8ebee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# label encoding\n",
    "from tensorflow.keras.utils import to_categorical # convert to one-hot-encoding\n",
    "y_train = to_categorical(y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6f6d46ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape (48000, 28, 28)\n",
      "x_test shape (12000, 28, 28)\n",
      "y_train shape (48000, 10)\n",
      "y_test shape (12000, 10)\n"
     ]
    }
   ],
   "source": [
    "# split the train and validation set for the fitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.2, random_state = 0)\n",
    "print(\"x_train shape\", x_train.shape)\n",
    "print(\"x_test shape\", x_test.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "cbc0069f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAMrklEQVR4nO3db6gV953H8c9ntYXECupGxU3zp6tCdtmEtIgstFkaSks2T0wJLvXBYtjC9UHdVCg0poE0sGwI2U02CYQmlgbdxU0pJNkECatBSrMbiOQmZBOtqFFse+tFMT5ozJMm+t0Hd9y91Tu/cz0z58y5ft8vuJxz5ntm5svBjzNz5sz8HBECcOX7o64bADAchB1IgrADSRB2IAnCDiQxf5grs81X/8CARYRnmt5oy277DtuHbH9ge2uTZQEYLPd7nt32PEmHJX1d0oSktyRtiIhfFuZhyw4M2CC27GslfRARxyLi95J+Kmldg+UBGKAmYb9W0m+mvZ6opv0B22O2x22PN1gXgIaafEE3067CJbvpEbFN0jaJ3XigS0227BOSrpv2+vOSTjRrB8CgNAn7W5JW2/6C7c9K+pakV9ppC0Db+t6Nj4hPbW+WtFvSPEnPRcSB1joD0Kq+T731tTKO2YGBG8iPagDMHYQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJPoen12SbB+X9JGkc5I+jYg1bTQFoH2Nwl65PSJOt7AcAAPEbjyQRNOwh6Q9tt+2PTbTG2yP2R63Pd5wXQAacET0P7P9JxFxwvYySa9J+vuIeL3w/v5XBmBWIsIzTW+0ZY+IE9XjKUkvSVrbZHkABqfvsNteYHvhheeSviFpf1uNAWhXk2/jl0t6yfaF5fx7RPxnK10BaF2jY/bLXhnH7MDADeSYHcDcQdiBJAg7kARhB5Ig7EASbVwIA8w5V199dbF+yy23DKmTS7355psDWS5bdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgvPsKJo/v/xP5PHHHy/WN27cWFsb5hWXF5s3b16xvmDBgkbL//jjj4v1M2fO1NZuuOGGRuuuw5YdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Lg7rIoWrp0abG+b9++Yv3QoUNtttOaPXv2NJr/6NGjxfr4eHm0sxMnTjRafwl3lwWSI+xAEoQdSIKwA0kQdiAJwg4kQdiBJDjPfoXrdd12r2unjx071mY7GIK+z7Pbfs72Kdv7p01bYvs120eqx8VtNgugfbPZjd8u6Y6Lpm2VtDciVkvaW70GMMJ6hj0iXpd08T101knaUT3fIemudtsC0LZ+70G3PCImJSkiJm0vq3uj7TFJY32uB0BLBn7DyYjYJmmbxBd0QJf6PfV20vYKSaoeT7XXEoBB6Dfsr0i6cI/gjZJebqcdAIPS8zy77eclfVXSNZJOSvqhpP+Q9DNJ10v6taT1EVF/I+z/Xxa78UN2//33F+ul+7pL0s0331ysf/LJJ5fdEwar7jx7z2P2iNhQU/pao44ADBU/lwWSIOxAEoQdSIKwA0kQdiAJhmy+Aqxfv762tnnz5uK8Dz/8cLF+/vz5vnrC6GHLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJcJ59Drj77ruL9R07dtTWnnjiieK8Tz/9dD8tYQ5iyw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTBk8whYtGhRsX7kyJFifeHChbW1l18u39J/YmKiWH/11VeL9b179xbrGL6+h2wGcGUg7EAShB1IgrADSRB2IAnCDiRB2IEkuJ59BNx0003F+tGjR4v1Q4cO1dZOnz5dnHfVqlXF+u7du4v17du3F+tbtmyprZ09e7Y4L9rVc8tu+znbp2zvnzbtIdu/tf1u9XfnYNsE0NRsduO3S7pjhun/EhG3Vn/ln1kB6FzPsEfE65LODKEXAAPU5Au6zbbfq3bzF9e9yfaY7XHb4w3WBaChfsP+I0krJd0qaVLSY3VvjIhtEbEmItb0uS4ALegr7BFxMiLORcR5ST+WtLbdtgC0ra+w214x7eU3Je2vey+A0dDzenbbz0v6qqRrJJ2U9MPq9a2SQtJxSZsiYrLnyriefc659957i/XHHqs9gpMk3XPPPbW1nTt39tMSeqi7nr3nj2oiYsMMk3/SuCMAQ8XPZYEkCDuQBGEHkiDsQBKEHUiCS1xRVBoOWpIeeOCBIXWCptiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASnGdH0W233VasX3XVVcU6QzqPDrbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BEz1tJt7qyOXwr6QMHDtTWnnrqqeK8zz77bNvttGbRokXF+htvvFGsL126tFhftmzZ5baEhupuJc2WHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS4Hr2Wbr++utra88880xx3ttvv71Yf/DBB4v1w4cPF+sla9euLdaffPLJYn316tXF+n333XfZPaEbPbfstq+z/XPbB20fsP3davoS26/ZPlI9Lh58uwD6NZvd+E8lfS8i/kzSX0r6ju0/l7RV0t6IWC1pb/UawIjqGfaImIyId6rnH0k6KOlaSeskXRgbaIekuwbUI4AWXNYxu+0bJX1R0j5JyyNiUpr6D8H2jD+Ctj0maaxhnwAamnXYbX9O0guStkTE7+wZf2t/iYjYJmlbtYw5eyEMMNfN6tSb7c9oKug7I+LFavJJ2yuq+gpJpwbTIoA29LzE1VOb8B2SzkTElmnT/0nShxHxiO2tkpZExPd7LGvObtk3bdpUW3v00UeL8y5cuLBYP3fuXLE+OTlZrH/44Ye1tVWrVhXnnT+/vHO3fv36Yn3Xrl3FOoav7hLX2ezGf1nS30p63/a71bQfSHpE0s9sf1vSryWV/1UA6FTPsEfEf0uqO0D/WrvtABgUfi4LJEHYgSQIO5AEYQeSIOxAEtxKugUrV64s1nvdbrlLExMTjeoYPdxKGkiOsANJEHYgCcIOJEHYgSQIO5AEYQeS4Dw7cIXhPDuQHGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4k0TPstq+z/XPbB20fsP3davpDtn9r+93q787BtwugXz1vXmF7haQVEfGO7YWS3pZ0l6S/kXQ2Iv551ivj5hXAwNXdvGI247NPSpqsnn9k+6Cka9ttD8CgXdYxu+0bJX1R0r5q0mbb79l+zvbimnnGbI/bHm/WKoAmZn0POtufk/QLSf8YES/aXi7ptKSQ9A+a2tX/ux7LYDceGLC63fhZhd32ZyTtkrQ7Ih6foX6jpF0R8Rc9lkPYgQHr+4aTti3pJ5IOTg969cXdBd+UtL9pkwAGZzbfxn9F0n9Jel/S+WryDyRtkHSrpnbjj0vaVH2ZV1oWW3ZgwBrtxreFsAODx33jgeQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSfS84WTLTkv61bTX11TTRtGo9jaqfUn01q82e7uhrjDU69kvWbk9HhFrOmugYFR7G9W+JHrr17B6YzceSIKwA0l0HfZtHa+/ZFR7G9W+JHrr11B66/SYHcDwdL1lBzAkhB1IopOw277D9iHbH9je2kUPdWwft/1+NQx1p+PTVWPonbK9f9q0JbZfs32kepxxjL2OehuJYbwLw4x3+tl1Pfz50I/Zbc+TdFjS1yVNSHpL0oaI+OVQG6lh+7ikNRHR+Q8wbP+VpLOS/vXC0Fq2H5V0JiIeqf6jXBwR941Ibw/pMofxHlBvdcOM36MOP7s2hz/vRxdb9rWSPoiIYxHxe0k/lbSugz5GXkS8LunMRZPXSdpRPd+hqX8sQ1fT20iIiMmIeKd6/pGkC8OMd/rZFfoaii7Cfq2k30x7PaHRGu89JO2x/bbtsa6bmcHyC8NsVY/LOu7nYj2H8R6mi4YZH5nPrp/hz5vqIuwzDU0zSuf/vhwRX5L015K+U+2uYnZ+JGmlpsYAnJT0WJfNVMOMvyBpS0T8rsteppuhr6F8bl2EfULSddNef17SiQ76mFFEnKgeT0l6SVOHHaPk5IURdKvHUx33838i4mREnIuI85J+rA4/u2qY8Rck7YyIF6vJnX92M/U1rM+ti7C/JWm17S/Y/qykb0l6pYM+LmF7QfXFiWwvkPQNjd5Q1K9I2lg93yjp5Q57+QOjMox33TDj6viz63z484gY+p+kOzX1jfxRSQ900UNNX38q6X+qvwNd9ybpeU3t1n2iqT2ib0v6Y0l7JR2pHpeMUG//pqmhvd/TVLBWdNTbVzR1aPiepHervzu7/uwKfQ3lc+PnskAS/IIOSIKwA0kQdiAJwg4kQdiBJAg7kARhB5L4XxLBC+K00rbOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[2][:,:],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e8c22372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d9bb00f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8f4d2671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape (48000, 28, 28, 1)\n",
      "x_test.shape (12000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train.shape\", x_train.shape)\n",
    "print(\"x_test.shape\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "59efffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 8, kernel_size = (3,3), activation = 'relu', input_shape = (28,28,1)))\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(300, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e0a03181",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 26, 26, 8)         80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 13, 13, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 1352)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 300)               405900    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 408,990\n",
      "Trainable params: 408,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2865cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "opd = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c11641f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = opd, loss = 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e57ad253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/125\n",
      "48000/48000 [==============================] - 24s 509us/sample - loss: 0.2380 - accuracy: 0.9288 - val_loss: 0.0899 - val_accuracy: 0.9732\n",
      "Epoch 2/125\n",
      "48000/48000 [==============================] - 23s 489us/sample - loss: 0.0866 - accuracy: 0.9737 - val_loss: 0.0598 - val_accuracy: 0.9824\n",
      "Epoch 3/125\n",
      "48000/48000 [==============================] - 24s 491us/sample - loss: 0.0600 - accuracy: 0.9822 - val_loss: 0.0622 - val_accuracy: 0.9806\n",
      "Epoch 4/125\n",
      "48000/48000 [==============================] - 23s 487us/sample - loss: 0.0434 - accuracy: 0.9856 - val_loss: 0.0499 - val_accuracy: 0.9843\n",
      "Epoch 5/125\n",
      "48000/48000 [==============================] - 23s 487us/sample - loss: 0.0331 - accuracy: 0.9889 - val_loss: 0.0455 - val_accuracy: 0.9850\n",
      "Epoch 6/125\n",
      "48000/48000 [==============================] - 24s 490us/sample - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.0551 - val_accuracy: 0.9842\n",
      "Epoch 7/125\n",
      "48000/48000 [==============================] - 23s 489us/sample - loss: 0.0228 - accuracy: 0.9924 - val_loss: 0.0501 - val_accuracy: 0.9852\n",
      "Epoch 8/125\n",
      "48000/48000 [==============================] - 24s 490us/sample - loss: 0.0185 - accuracy: 0.9937 - val_loss: 0.0480 - val_accuracy: 0.9879\n",
      "Epoch 9/125\n",
      "48000/48000 [==============================] - 24s 490us/sample - loss: 0.0164 - accuracy: 0.9950 - val_loss: 0.0517 - val_accuracy: 0.9860\n",
      "Epoch 10/125\n",
      "48000/48000 [==============================] - 23s 489us/sample - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.0526 - val_accuracy: 0.9862\n",
      "Epoch 11/125\n",
      "48000/48000 [==============================] - 24s 492us/sample - loss: 0.0130 - accuracy: 0.9955 - val_loss: 0.0476 - val_accuracy: 0.9866\n",
      "Epoch 12/125\n",
      "48000/48000 [==============================] - 23s 489us/sample - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.0552 - val_accuracy: 0.9868\n",
      "Epoch 13/125\n",
      "48000/48000 [==============================] - 24s 491us/sample - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.0536 - val_accuracy: 0.9872\n",
      "Epoch 14/125\n",
      "48000/48000 [==============================] - 23s 488us/sample - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.0545 - val_accuracy: 0.9872\n",
      "Epoch 15/125\n",
      "48000/48000 [==============================] - 23s 488us/sample - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.0533 - val_accuracy: 0.9878\n",
      "Epoch 16/125\n",
      "48000/48000 [==============================] - 23s 489us/sample - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.0540 - val_accuracy: 0.9872\n",
      "Epoch 17/125\n",
      "48000/48000 [==============================] - 24s 491us/sample - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.0553 - val_accuracy: 0.9881\n",
      "Epoch 18/125\n",
      "48000/48000 [==============================] - 24s 495us/sample - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.0550 - val_accuracy: 0.9878\n",
      "Epoch 19/125\n",
      "48000/48000 [==============================] - 24s 493us/sample - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0631 - val_accuracy: 0.9869\n",
      "Epoch 20/125\n",
      "48000/48000 [==============================] - 23s 487us/sample - loss: 0.0070 - accuracy: 0.9975 - val_loss: 0.0647 - val_accuracy: 0.9867\n",
      "Epoch 21/125\n",
      "48000/48000 [==============================] - 23s 489us/sample - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.0620 - val_accuracy: 0.9880\n",
      "Epoch 22/125\n",
      "48000/48000 [==============================] - 24s 492us/sample - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.0674 - val_accuracy: 0.9877\n",
      "Epoch 23/125\n",
      "48000/48000 [==============================] - 23s 489us/sample - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.0568 - val_accuracy: 0.9886\n",
      "Epoch 24/125\n",
      "48000/48000 [==============================] - 23s 489us/sample - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.0669 - val_accuracy: 0.9876\n",
      "Epoch 25/125\n",
      "48000/48000 [==============================] - 23s 489us/sample - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.0636 - val_accuracy: 0.9885\n",
      "Epoch 26/125\n",
      "48000/48000 [==============================] - 24s 490us/sample - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0628 - val_accuracy: 0.9883\n",
      "Epoch 27/125\n",
      "48000/48000 [==============================] - 24s 502us/sample - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0709 - val_accuracy: 0.9882\n",
      "Epoch 28/125\n",
      "48000/48000 [==============================] - 24s 498us/sample - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0669 - val_accuracy: 0.9879\n",
      "Epoch 29/125\n",
      "48000/48000 [==============================] - 23s 488us/sample - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0684 - val_accuracy: 0.9891\n",
      "Epoch 30/125\n",
      "48000/48000 [==============================] - 25s 524us/sample - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.0849 - val_accuracy: 0.9877\n",
      "Epoch 31/125\n",
      "48000/48000 [==============================] - 25s 524us/sample - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0801 - val_accuracy: 0.9868\n",
      "Epoch 32/125\n",
      "48000/48000 [==============================] - 26s 532us/sample - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.0734 - val_accuracy: 0.9879\n",
      "Epoch 33/125\n",
      "48000/48000 [==============================] - 25s 528us/sample - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.0723 - val_accuracy: 0.9876\n",
      "Epoch 34/125\n",
      "48000/48000 [==============================] - 26s 537us/sample - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0794 - val_accuracy: 0.9876\n",
      "Epoch 35/125\n",
      "48000/48000 [==============================] - 25s 521us/sample - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0976 - val_accuracy: 0.9872\n",
      "Epoch 36/125\n",
      "48000/48000 [==============================] - 24s 505us/sample - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0713 - val_accuracy: 0.9875\n",
      "Epoch 37/125\n",
      "48000/48000 [==============================] - 24s 501us/sample - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0711 - val_accuracy: 0.9882\n",
      "Epoch 38/125\n",
      "48000/48000 [==============================] - 25s 525us/sample - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0759 - val_accuracy: 0.9881\n",
      "Epoch 39/125\n",
      "48000/48000 [==============================] - 24s 504us/sample - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0785 - val_accuracy: 0.9880\n",
      "Epoch 40/125\n",
      "48000/48000 [==============================] - 24s 499us/sample - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0730 - val_accuracy: 0.9895\n",
      "Epoch 41/125\n",
      "48000/48000 [==============================] - 24s 507us/sample - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0867 - val_accuracy: 0.9875\n",
      "Epoch 42/125\n",
      "48000/48000 [==============================] - 24s 492us/sample - loss: 0.0035 - accuracy: 0.9986 - val_loss: 0.0802 - val_accuracy: 0.9884\n",
      "Epoch 43/125\n",
      "48000/48000 [==============================] - 25s 511us/sample - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0916 - val_accuracy: 0.9873\n",
      "Epoch 44/125\n",
      "48000/48000 [==============================] - 24s 491us/sample - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0781 - val_accuracy: 0.9881\n",
      "Epoch 45/125\n",
      "48000/48000 [==============================] - 24s 491us/sample - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0775 - val_accuracy: 0.9877\n",
      "Epoch 46/125\n",
      "48000/48000 [==============================] - 25s 515us/sample - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0776 - val_accuracy: 0.9885\n",
      "Epoch 47/125\n",
      "48000/48000 [==============================] - 25s 510us/sample - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0768 - val_accuracy: 0.9882\n",
      "Epoch 48/125\n",
      "48000/48000 [==============================] - 24s 505us/sample - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0898 - val_accuracy: 0.9877\n",
      "Epoch 49/125\n",
      "48000/48000 [==============================] - 24s 498us/sample - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0838 - val_accuracy: 0.9874\n",
      "Epoch 50/125\n",
      "48000/48000 [==============================] - 24s 498us/sample - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0949 - val_accuracy: 0.9868\n",
      "Epoch 51/125\n",
      "48000/48000 [==============================] - 24s 499us/sample - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0906 - val_accuracy: 0.9878\n",
      "Epoch 52/125\n",
      "48000/48000 [==============================] - 25s 525us/sample - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0753 - val_accuracy: 0.9890\n",
      "Epoch 53/125\n",
      "48000/48000 [==============================] - 24s 502us/sample - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0911 - val_accuracy: 0.9886\n",
      "Epoch 54/125\n",
      "48000/48000 [==============================] - 23s 487us/sample - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0871 - val_accuracy: 0.9881\n",
      "Epoch 55/125\n",
      "48000/48000 [==============================] - 25s 524us/sample - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0791 - val_accuracy: 0.9899\n",
      "Epoch 56/125\n",
      "48000/48000 [==============================] - 23s 489us/sample - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0874 - val_accuracy: 0.9873\n",
      "Epoch 57/125\n",
      "48000/48000 [==============================] - 25s 521us/sample - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0899 - val_accuracy: 0.9875\n",
      "Epoch 58/125\n",
      "48000/48000 [==============================] - 25s 522us/sample - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0837 - val_accuracy: 0.9887\n",
      "Epoch 59/125\n",
      "48000/48000 [==============================] - 25s 512us/sample - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0828 - val_accuracy: 0.9887\n",
      "Epoch 60/125\n",
      "48000/48000 [==============================] - 24s 505us/sample - loss: 0.0022 - accuracy: 0.9991 - val_loss: 0.0880 - val_accuracy: 0.9886\n",
      "Epoch 61/125\n",
      "48000/48000 [==============================] - 24s 493us/sample - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0918 - val_accuracy: 0.9882\n",
      "Epoch 62/125\n",
      "48000/48000 [==============================] - 23s 487us/sample - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0874 - val_accuracy: 0.9887\n",
      "Epoch 63/125\n",
      "48000/48000 [==============================] - 24s 505us/sample - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0994 - val_accuracy: 0.9884\n",
      "Epoch 64/125\n",
      "48000/48000 [==============================] - 24s 507us/sample - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0929 - val_accuracy: 0.9887\n",
      "Epoch 65/125\n",
      "48000/48000 [==============================] - 25s 515us/sample - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.1024 - val_accuracy: 0.9868\n",
      "Epoch 66/125\n",
      "48000/48000 [==============================] - 24s 502us/sample - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0902 - val_accuracy: 0.9889\n",
      "Epoch 67/125\n",
      "48000/48000 [==============================] - 24s 495us/sample - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0890 - val_accuracy: 0.9877\n",
      "Epoch 68/125\n",
      "48000/48000 [==============================] - 24s 490us/sample - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.1069 - val_accuracy: 0.9871\n",
      "Epoch 69/125\n",
      "48000/48000 [==============================] - 24s 490us/sample - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0896 - val_accuracy: 0.9887\n",
      "Epoch 70/125\n",
      "48000/48000 [==============================] - 24s 491us/sample - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0817 - val_accuracy: 0.9893\n",
      "Epoch 71/125\n",
      "48000/48000 [==============================] - 23s 489us/sample - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0927 - val_accuracy: 0.9897\n",
      "Epoch 72/125\n",
      "48000/48000 [==============================] - 24s 502us/sample - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.1137 - val_accuracy: 0.9891\n",
      "Epoch 73/125\n",
      "48000/48000 [==============================] - 24s 497us/sample - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0875 - val_accuracy: 0.9887\n",
      "Epoch 74/125\n",
      "48000/48000 [==============================] - 24s 501us/sample - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0966 - val_accuracy: 0.9893\n",
      "Epoch 75/125\n",
      "48000/48000 [==============================] - 23s 488us/sample - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.0942 - val_accuracy: 0.9878\n",
      "Epoch 76/125\n",
      "48000/48000 [==============================] - 23s 489us/sample - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.1076 - val_accuracy: 0.9887\n",
      "Epoch 77/125\n",
      "48000/48000 [==============================] - 24s 491us/sample - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0863 - val_accuracy: 0.9901\n",
      "Epoch 78/125\n",
      "48000/48000 [==============================] - 24s 493us/sample - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0981 - val_accuracy: 0.9890\n",
      "Epoch 79/125\n",
      "48000/48000 [==============================] - 24s 491us/sample - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0971 - val_accuracy: 0.9878\n",
      "Epoch 80/125\n",
      "48000/48000 [==============================] - 24s 492us/sample - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0973 - val_accuracy: 0.9885\n",
      "Epoch 81/125\n",
      "48000/48000 [==============================] - 28s 578us/sample - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0945 - val_accuracy: 0.9877\n",
      "Epoch 82/125\n",
      "48000/48000 [==============================] - 25s 521us/sample - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.1298 - val_accuracy: 0.9864\n",
      "Epoch 83/125\n",
      "48000/48000 [==============================] - 25s 514us/sample - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0918 - val_accuracy: 0.9888\n",
      "Epoch 84/125\n",
      "48000/48000 [==============================] - 25s 521us/sample - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0985 - val_accuracy: 0.9882\n",
      "Epoch 85/125\n",
      "48000/48000 [==============================] - 25s 515us/sample - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.1003 - val_accuracy: 0.9878\n",
      "Epoch 86/125\n",
      "48000/48000 [==============================] - 24s 508us/sample - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.1014 - val_accuracy: 0.9891\n",
      "Epoch 87/125\n",
      "48000/48000 [==============================] - 24s 508us/sample - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.1265 - val_accuracy: 0.9871\n",
      "Epoch 88/125\n",
      "48000/48000 [==============================] - 25s 516us/sample - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0983 - val_accuracy: 0.9899\n",
      "Epoch 89/125\n",
      "48000/48000 [==============================] - 25s 516us/sample - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.1112 - val_accuracy: 0.9889\n",
      "Epoch 90/125\n",
      "48000/48000 [==============================] - 25s 514us/sample - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.1020 - val_accuracy: 0.9895\n",
      "Epoch 91/125\n",
      "48000/48000 [==============================] - 25s 512us/sample - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.1080 - val_accuracy: 0.9884\n",
      "Epoch 92/125\n",
      "48000/48000 [==============================] - 25s 513us/sample - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0944 - val_accuracy: 0.9899\n",
      "Epoch 93/125\n",
      "48000/48000 [==============================] - 25s 514us/sample - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.1057 - val_accuracy: 0.9888\n",
      "Epoch 94/125\n",
      "48000/48000 [==============================] - 25s 513us/sample - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.1076 - val_accuracy: 0.9886\n",
      "Epoch 95/125\n",
      "48000/48000 [==============================] - 24s 509us/sample - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.1066 - val_accuracy: 0.9884\n",
      "Epoch 96/125\n",
      "48000/48000 [==============================] - 25s 512us/sample - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.1156 - val_accuracy: 0.9890\n",
      "Epoch 97/125\n",
      "48000/48000 [==============================] - 25s 515us/sample - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.1094 - val_accuracy: 0.9879\n",
      "Epoch 98/125\n",
      "48000/48000 [==============================] - 25s 510us/sample - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.1338 - val_accuracy: 0.9862\n",
      "Epoch 99/125\n",
      "48000/48000 [==============================] - 25s 511us/sample - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.1115 - val_accuracy: 0.9878\n",
      "Epoch 100/125\n",
      "48000/48000 [==============================] - 24s 491us/sample - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.1189 - val_accuracy: 0.9884\n",
      "Epoch 101/125\n",
      "48000/48000 [==============================] - 23s 477us/sample - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.1174 - val_accuracy: 0.9879\n",
      "Epoch 102/125\n",
      "48000/48000 [==============================] - 23s 477us/sample - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.1163 - val_accuracy: 0.9877\n",
      "Epoch 103/125\n",
      "48000/48000 [==============================] - 23s 482us/sample - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.1150 - val_accuracy: 0.9875\n",
      "Epoch 104/125\n",
      "48000/48000 [==============================] - 23s 475us/sample - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.1057 - val_accuracy: 0.9886\n",
      "Epoch 105/125\n",
      "48000/48000 [==============================] - 23s 474us/sample - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.1221 - val_accuracy: 0.9877\n",
      "Epoch 106/125\n",
      "48000/48000 [==============================] - 23s 474us/sample - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.1165 - val_accuracy: 0.9884\n",
      "Epoch 107/125\n",
      "48000/48000 [==============================] - 23s 474us/sample - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.1114 - val_accuracy: 0.9877\n",
      "Epoch 108/125\n",
      "48000/48000 [==============================] - 23s 475us/sample - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.1202 - val_accuracy: 0.9877\n",
      "Epoch 109/125\n",
      "48000/48000 [==============================] - 23s 477us/sample - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.1215 - val_accuracy: 0.9885\n",
      "Epoch 110/125\n",
      "48000/48000 [==============================] - 23s 475us/sample - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.1161 - val_accuracy: 0.9887\n",
      "Epoch 111/125\n",
      "48000/48000 [==============================] - 23s 474us/sample - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.1270 - val_accuracy: 0.9879\n",
      "Epoch 112/125\n",
      "48000/48000 [==============================] - 23s 473us/sample - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.1162 - val_accuracy: 0.9885\n",
      "Epoch 113/125\n",
      "48000/48000 [==============================] - 23s 475us/sample - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.1197 - val_accuracy: 0.9885\n",
      "Epoch 114/125\n",
      "48000/48000 [==============================] - 23s 474us/sample - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.1190 - val_accuracy: 0.9883\n",
      "Epoch 115/125\n",
      "48000/48000 [==============================] - 23s 474us/sample - loss: 7.6054e-04 - accuracy: 0.9998 - val_loss: 0.1255 - val_accuracy: 0.9889\n",
      "Epoch 116/125\n",
      "48000/48000 [==============================] - 23s 478us/sample - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.1418 - val_accuracy: 0.9868\n",
      "Epoch 117/125\n",
      "48000/48000 [==============================] - 23s 474us/sample - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.1319 - val_accuracy: 0.9877\n",
      "Epoch 118/125\n",
      "48000/48000 [==============================] - 23s 472us/sample - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.1271 - val_accuracy: 0.9880\n",
      "Epoch 119/125\n",
      "48000/48000 [==============================] - 23s 475us/sample - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.1264 - val_accuracy: 0.9883\n",
      "Epoch 120/125\n",
      "48000/48000 [==============================] - 23s 475us/sample - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1509 - val_accuracy: 0.9869\n",
      "Epoch 121/125\n",
      "48000/48000 [==============================] - 23s 474us/sample - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.1250 - val_accuracy: 0.9890\n",
      "Epoch 122/125\n",
      "48000/48000 [==============================] - 23s 473us/sample - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.1417 - val_accuracy: 0.9868\n",
      "Epoch 123/125\n",
      "48000/48000 [==============================] - 23s 487us/sample - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.1237 - val_accuracy: 0.9878\n",
      "Epoch 124/125\n",
      "48000/48000 [==============================] - 23s 473us/sample - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.1212 - val_accuracy: 0.9877\n",
      "Epoch 125/125\n",
      "48000/48000 [==============================] - 23s 472us/sample - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.1196 - val_accuracy: 0.9873\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, batch_size = 28, epochs = 125, validation_data=(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
